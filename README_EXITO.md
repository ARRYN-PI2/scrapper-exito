# üõí Scraper Exito.com

## üìã Comandos completos por categor√≠a

### üì± Celulares
```bash
python -m exito_scraper.main scrape --categoria celulares --paginas 10 --output data/celulares.json
python -m exito_scraper.main scrape --categoria celulares --paginas 5 --output data/celulares.csv
```

### üì∫ Televisores
```bash
python -m exito_scraper.main scrape --categoria televisores --paginas 15 --output data/televisores.json
python -m exito_scraper.main scrape --categoria televisores --paginas 8 --output data/televisores.csv
```

### üß∫ Lavadoras
```bash
python -m exito_scraper.main scrape --categoria lavadoras --paginas 12 --output data/lavadoras.json
python -m exito_scraper.main scrape --categoria lavadoras --paginas 5 --output data/lavadoras.csv
```

### ‚ùÑÔ∏è Refrigeraci√≥n
```bash
python -m exito_scraper.main scrape --categoria refrigeracion --paginas 10 --output data/refrigeradores.json
python -m exito_scraper.main scrape --categoria refrigeracion --paginas 7 --output data/refrigeradores.csv
```

### üîä Audio
```bash
python -m exito_scraper.main scrape --categoria audio --paginas 8 --output data/audio.json
python -m exito_scraper.main scrape --categoria audio --paginas 6 --output data/audio.csv
```

### üéÆ Videojuegos
```bash
python -m exito_scraper.main scrape --categoria videojuegos --paginas 12 --output data/videojuegos.json
python -m exito_scraper.main scrape --categoria videojuegos --paginas 5 --output data/videojuegos.csv
```

### üèÉ Deportes
```bash
python -m exito_scraper.main scrape --categoria deportes --paginas 20 --output data/deportes.json
python -m exito_scraper.main scrape --categoria deportes --paginas 10 --output data/deportes.csv
```

---

‚≠ê **Por defecto se genera JSON con calificaciones incluidas**  
üìÑ Los productos sin calificaci√≥n muestran "No tiene Calificacion"
```

### Instalaci√≥n Local

```bash
# Instalar dependencias
pip install -r requirements.txt

# Ejecutar scraper
python -m exito_scraper.main scrape --categoria televisores --paginas 2

# Instalar dependencias
pip install -r requirements.txt

```

## Ejemplo de Datos Extra√≠dos

El scraper extrae **17 campos completos** por producto:

```json
{
  "titulo": "Televisor LG 55\" 4K UHD Smart TV",
  "precio": "$1.299.900",
  "precio_original": "$1.599.900",
  "descuento": "19%",
  "descripcion": "Televisor LG con tecnolog√≠a 4K UHD y Smart TV webOS",
  "sku": "LG55UP7500PSB",
  "marca": "LG",
  "modelo": "55UP7500PSB",
  "disponibilidad": "En stock",
  "calificacion": "4.5",
  "numero_resenas": "342",
  "imagen_principal": "https://www.exito.com/medias/...",
  "imagenes_adicionales": ["https://...", "https://..."],
  "categoria": "Televisores",
  "subcategoria": "Smart TV",
  "detalles_adicionales": "Pantalla: 55 pulgadas. Resoluci√≥n: 4K UHD (3840x2160)...",
  "link": "https://www.exito.com/televisor-lg-55-4k-uhd-smart-tv"
}
```

### Estad√≠sticas de Completitud

- **98-100%** de campos b√°sicos (t√≠tulo, precio, link)
- **95-98%** de campos descriptivos (marca, modelo, disponibilidad)  
- **90-95%** de campos adicionales (im√°genes, reviews)
- **HTML limpiado** autom√°ticamente en descripciones

## Casos de Uso

### Ejecuci√≥n Programada

```bash
# Cron job diario a las 6 AM
0 6 * * * cd /path/to/scraper && docker-compose run --rm exito-scraper scrape --categoria televisores --paginas 5
```

### Para Empresas

```bash
# Monitoreo de precios de competencia
python -m exito_scraper.main scrape --categoria "computadores portatiles" --paginas 10

# An√°lisis de inventario
python -m exito_scraper.main scrape --categoria celulares --paginas 5
```

## Configuraci√≥n

### Variables de Entorno

```bash
# .env
SCRAPER_DELAY=2          # Delay entre requests
SCRAPER_RETRIES=3        # N√∫mero de reintentos  
LOG_LEVEL=INFO           # Nivel de logging
OUTPUT_FORMAT=both       # jsonl, json, both
```

## Estructura del Proyecto

```
scrapper-exito/
‚îú‚îÄ‚îÄ exito_scraper/          # C√≥digo principal
‚îÇ   ‚îú‚îÄ‚îÄ adapters/           # Adaptadores (scraper, repos)
‚îÇ   ‚îú‚îÄ‚îÄ application/        # Casos de uso
‚îÇ   ‚îú‚îÄ‚îÄ domain/            # L√≥gica de dominio
‚îÇ   ‚îú‚îÄ‚îÄ utils/             # Utilidades (HTML cleaning)
‚îÇ   ‚îú‚îÄ‚îÄ config.py          # Configuraci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ main.py            # CLI principal
‚îú‚îÄ‚îÄ .github/workflows/      # Pipeline CI/CD
‚îú‚îÄ‚îÄ data/                  # Archivos extra√≠dos
‚îú‚îÄ‚îÄ Dockerfile             # Imagen Docker
‚îú‚îÄ‚îÄ docker-compose.yml     # Orquestaci√≥n
‚îú‚îÄ‚îÄ requirements.txt       # Dependencias
‚îú‚îÄ‚îÄ USAGE.md              # Gu√≠a completa de uso
‚îî‚îÄ‚îÄ DOCKER.md             # Documentaci√≥n Docker

## Limpieza de Datos

El scraper incluye limpieza autom√°tica de HTML:

### Antes (HTML crudo)
```html
<p><span>*No se ofrece servicio de instalaci√≥n.</span></p>
<p><span>El dise√±o de brazo extensible hace...</span></p>
```

### Despu√©s (texto limpio)
```
*No se ofrece servicio de instalaci√≥n.

El dise√±o de brazo extensible hace que el modelo sea mucho m√°s fuerte...
```

### Utilidades Adicionales

```bash
# Limpiar archivos existentes
python clean_existing_json.py data/productos.jsonl

# Convertir JSONL a JSON formateado
python format_json.py data/productos.jsonl
```

## Formatos de Salida

### JSONL (Compacto)
```json
{"titulo": "TV Samsung 55\"", "precio_valor": 1200000, "marca": "SAMSUNG"}
{"titulo": "TV LG 43\"", "precio_valor": 800000, "marca": "LG"}
```

### JSON Formateado (Legible)
```json
[
  {
    "titulo": "TV Samsung 55\"",
    "precio_valor": 1200000,
    "marca": "SAMSUNG",
    "detalles_adicionales": "Smart TV con tecnolog√≠a 4K..."
  }
]
```

## Configuraci√≥n

### Variables de Entorno (.env)

```bash
# Versiones Python para CI/CD
PYTHON_VERSION_MAIN=3.11
PYTHON_VERSIONS=["3.9", "3.10", "3.11", "3.12"]

# Configuraci√≥n Docker
DOCKER_IMAGE_NAME=exito-scraper
DOCKER_TAG=latest

# Configuraci√≥n del scraper
DEFAULT_TIMEOUT=30
DEFAULT_DELAY=2
```

### Personalizaci√≥n

Edita `exito_scraper/config.py` para:
- Agregar nuevas categor√≠as
- Modificar headers HTTP
- Ajustar timeouts y delays

## Docker

### Construcci√≥n

```bash
# Construcci√≥n simple
docker build -t exito-scraper .

# Construcci√≥n con tests
./docker-build.sh

# Con versi√≥n espec√≠fica
./docker-build.sh v1.0.0
```

### Ejecuci√≥n

```bash
# Scraping b√°sico
docker run --rm -v $(pwd)/data:/app/data exito-scraper \
  python -m exito_scraper.main scrape --categoria televisores --paginas 1 --output data/tv.jsonl

# Shell interactivo
docker run --rm -it -v $(pwd)/data:/app/data exito-scraper /bin/bash

# Con variables de entorno
docker run --rm --env-file .env -v $(pwd)/data:/app/data exito-scraper \
  python -m exito_scraper.main scrape --categoria celulares --paginas 1 --output data/phones.jsonl
```

## CI/CD Pipeline

El pipeline autom√°tico incluye:

1. **Setup**: Lee versiones Python desde `.env`
2. **Lint & Format**: Black, isort, flake8, mypy
3. **Test**: Pruebas en m√∫ltiples versiones Python
4. **Security**: Escaneo con safety y bandit
5. **Docker Build**: Construcci√≥n y prueba de imagen
6. **Integration Tests**: Pruebas de integraci√≥n
7. **Release**: Creaci√≥n autom√°tica de releases

### Activaci√≥n

```bash
# Push a main/develop activa el pipeline
git push origin main

# Manual trigger
gh workflow run ci-cd.yml
```

## Arquitectura

### Patrones Utilizados

- **Ports & Adapters**: Separaci√≥n clara de responsabilidades
- **Repository Pattern**: Abstracci√≥n de persistencia  
- **Command Pattern**: CLI estructurado
- **Strategy Pattern**: M√∫ltiples formatos de salida

### Componentes Principales

1. **Domain**: Entidades (`Producto`) y puertos
2. **Application**: Casos de uso (`ScrapeUseCase`)
3. **Adapters**: Implementaciones concretas

---

## Enlaces R√°pidos

| Documento | Descripci√≥n | Audiencia |
|-----------|-------------|-----------|
| **[USAGE.md](./USAGE.md)** | Gu√≠a completa de uso y deployment | Todos los roles |
| **[DOCKER.md](./DOCKER.md)** | Documentaci√≥n de Docker | Desarrolladores |
| **[CI/CD Pipeline](./.github/workflows/ci-cd.yml)** | Configuraci√≥n de automatizaci√≥n | DevOps |
| **[requirements.txt](./requirements.txt)** | Dependencias del proyecto | Desarrolladores |

## Uso R√°pido por Rol

### Ejecutor/Operador
```bash
# Ejecutar scraper diariamente
docker-compose run --rm exito-scraper scrape --categoria televisores --paginas 5
```

### Desarrollador  
```bash
# Setup local
pip install -r requirements.txt
python -m exito_scraper.main scrape --categoria televisores --debug
```

### Arquitecto AWS
```bash
# Deploy a ECS Fargate
aws ecs register-task-definition --cli-input-json file://task-definition.json
```

---

**¬°Listo para usar!** - Ver [USAGE.md](./USAGE.md) para instrucciones detalladas
4. **Utils**: Utilidades transversales

## Testing

```bash
# Tests locales (cuando est√©n disponibles)
pytest tests/ -v --cov=exito_scraper

# Tests en Docker
docker-compose run --rm test-runner

# Tests del pipeline
./docker-build.sh
```

## Datos Extra√≠dos

Cada producto incluye:

- **Informaci√≥n b√°sica**: t√≠tulo, marca, categor√≠a
- **Precios**: texto y valor num√©rico, moneda
- **Metadatos**: imagen, link, fecha de extracci√≥n
- **Detalles**: descripci√≥n limpia (sin HTML)
- **T√©cnicos**: contadores, estado de extracci√≥n

### Estad√≠sticas de Calidad

- **Campos b√°sicos**: 100% cobertura
- **Precios**: 98% cobertura
- **Detalles**: 64% cobertura
- **Tama√±os**: 86% cobertura (solo TVs)


